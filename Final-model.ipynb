{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n# from torchvision.models import vgg16\nimport torchvision.models as models\nfrom skimage.metrics import structural_similarity as compare_ssim\nfrom skimage.metrics import peak_signal_noise_ratio as compare_psnr\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport numpy as np\nimport glob\nimport random\nimport numbers\nimport cv2\nfrom torch.autograd import Variable\nimport torch.utils.data as data\nfrom torch.utils.data import random_split\nimport skimage\ndata_dir = '/kaggle/input/euvp-dataset/EUVP Dataset/Paired'","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:01:27.720625Z","iopub.execute_input":"2023-04-14T06:01:27.721173Z","iopub.status.idle":"2023-04-14T06:01:31.013560Z","shell.execute_reply.started":"2023-04-14T06:01:27.721119Z","shell.execute_reply":"2023-04-14T06:01:31.012460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = 'output_images'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T06:01:31.015278Z","iopub.execute_input":"2023-04-14T06:01:31.015832Z","iopub.status.idle":"2023-04-14T06:01:31.021000Z","shell.execute_reply.started":"2023-04-14T06:01:31.015794Z","shell.execute_reply":"2023-04-14T06:01:31.019611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class UnderwaterCNN(nn.Module):\n    def __init__(self):\n        super(UnderwaterCNN, self).__init__()\n        \n        # First stage - Dehazing\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.relu1 = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.relu2 = nn.ReLU(inplace=True)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.relu3 = nn.ReLU(inplace=True)\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.relu4 = nn.ReLU(inplace=True)\n        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')\n        \n        # Second stage - Color Correction\n        self.conv5 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n        self.bn5 = nn.BatchNorm2d(32)\n        self.relu5 = nn.ReLU(inplace=True)\n        self.conv6 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        self.bn6 = nn.BatchNorm2d(64)\n        self.relu6 = nn.ReLU(inplace=True)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv7 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.bn7 = nn.BatchNorm2d(128)\n        self.relu7 = nn.ReLU(inplace=True)\n        self.conv8 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1)\n        self.bn8 = nn.BatchNorm2d(64)\n        self.relu8 = nn.ReLU(inplace=True)\n        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')\n        \n        # Third stage - Image Enhancement\n        self.conv9 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding=1)\n        self.bn9 = nn.BatchNorm2d(32)\n        self.relu9 = nn.ReLU(inplace=True)\n        self.conv10 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        self.bn10 = nn.BatchNorm2d(64)\n        self.relu10 = nn.ReLU(inplace=True)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv11 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.bn11 = nn.BatchNorm2d(128)\n        self.relu11 = nn.ReLU(inplace=True)\n        self.conv12 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1)\n        self.bn12 = nn.BatchNorm2d(64)\n        self.relu12 = nn.ReLU(inplace=True)\n        self.conv13 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n        self.bn13 = nn.BatchNorm2d(128)\n        self.relu13 = nn.ReLU(inplace=True)\n        self.conv14 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding=1)\n        self.bn14 = nn.BatchNorm2d(64)\n        self.relu14 = nn.ReLU(inplace=True)\n        self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')\n        \n        # Output\n        self.conv15 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=1, padding=0)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n           \n        # First stage - Dehazing\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.maxpool1(x)\n        x = self.conv3(x)\n        x = self.bn3(x)\n        x = self.relu3(x)\n        x = self.conv4(x)\n        x = self.bn4(x)\n        x = self.relu4(x)\n        x = self.upsample1(x)\n        \n        # Second stage - Color Correction\n        x = self.conv5(x)\n        x = self.bn5(x)\n        x = self.relu5(x)\n        x = self.conv6(x)\n        x = self.bn6(x)\n        x = self.relu6(x)\n        x = self.maxpool2(x)\n        x = self.conv7(x)\n        x = self.bn7(x)\n        x = self.relu7(x)\n        x = self.conv8(x)\n        x = self.bn8(x)\n        x = self.relu8(x)\n        x = self.upsample2(x)\n        \n        # Third stage - Image Enhancement\n        x = self.conv9(x)\n        x = self.bn9(x)\n        x = self.relu9(x)\n        x = self.conv10(x)\n        x = self.bn10(x)\n        x = self.relu10(x)\n        x = self.maxpool3(x)\n        x = self.conv11(x)\n        x = self.bn11(x)\n        x = self.relu11(x)\n        x = self.conv12(x)\n        x = self.bn12(x)\n        x = self.relu12(x)\n        x = self.conv13(x)\n        x = self.bn13(x)\n        x = self.relu13(x)\n        x = self.conv14(x)\n        x = self.bn14(x)\n        x = self.relu14(x)\n        x = self.upsample3(x)\n        # Output\n        x = self.conv15(x)\n        x = self.sigmoid(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-04-11T09:46:49.450285Z","iopub.execute_input":"2023-04-11T09:46:49.450872Z","iopub.status.idle":"2023-04-11T09:46:49.494738Z","shell.execute_reply.started":"2023-04-11T09:46:49.450829Z","shell.execute_reply":"2023-04-11T09:46:49.493630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Processing","metadata":{}},{"cell_type":"code","source":"class ToTensor(object):\n    def __call__(self, sample):\n        hazy_image, clean_image = sample['hazy'], sample['clean']\n        hazy_image = np.array(hazy_image)\n        hazy_image = torch.from_numpy(hazy_image.astype(np.float32))\n        hazy_image = torch.transpose(torch.transpose(hazy_image, 2, 0), 1, 2)\n        clean_image = np.array(clean_image)\n        clean_image = torch.from_numpy(clean_image.astype(np.float32))\n        clean_image = torch.transpose(torch.transpose(clean_image, 2, 0), 1, 2)\n        return {'hazy': hazy_image,\n                'clean': clean_image}\n\n\n\nclass EUVP_Dataset(Dataset):\n    def __init__(self, data_dir, transform=None):\n        self.data_dir = data_dir\n        self.filesA, self.filesB = self.get_file_paths(self.data_dir)\n        self.len = min(len(self.filesA), len(self.filesB))\n        self.transform = transform\n      \n    def __len__(self):\n        return self.len\n\n    def __getitem__(self, index):\n        hazy_im = cv2.resize(cv2.imread(self.filesA[index % self.len]), (256,256),\n                                 interpolation=cv2.INTER_AREA)\n\n        hazy_im = hazy_im[:, :, ::-1]    \n        hazy_im = np.float32(hazy_im) / 255.0\n\n\n        clean_im = cv2.resize(cv2.imread(self.filesB[index % self.len]), (256,256),\n                                  interpolation=cv2.INTER_AREA)\n\n        clean_im = clean_im[:, :, ::-1]  \n        clean_im = np.float32(clean_im) / 255.0\n\n        sample = {'hazy': hazy_im, \n                  'clean': clean_im}    \n        if self.transform != None:\n            sample = self.transform(sample)\n    \n        return sample\n\n\n    def get_file_paths(self, data_dir):\n        sub_dirs = ['underwater_imagenet', 'underwater_dark', 'underwater_scenes']\n        filesA, filesB = [], []\n        for sd in sub_dirs:\n            filesA += sorted(glob.glob(os.path.join(data_dir, sd, 'trainA') + \"/*.*\"))\n            filesB += sorted(glob.glob(os.path.join(data_dir, sd, 'trainB') + \"/*.*\"))\n        return filesA, filesB ","metadata":{"execution":{"iopub.status.busy":"2023-04-11T09:46:49.500602Z","iopub.execute_input":"2023-04-11T09:46:49.502898Z","iopub.status.idle":"2023-04-11T09:46:49.527639Z","shell.execute_reply.started":"2023-04-11T09:46:49.502862Z","shell.execute_reply":"2023-04-11T09:46:49.526869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    train_loss = 0\n    for i, data in enumerate(dataloader, 0):\n        input_img, target = data['input_img'].to(device), data['target'].to(device)\n        optimizer.zero_grad()\n        output = model(input_img)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n    avg_loss = train_loss / len(dataloader)\n    return avg_loss","metadata":{"execution":{"iopub.status.busy":"2023-04-11T09:46:49.548873Z","iopub.execute_input":"2023-04-11T09:46:49.549277Z","iopub.status.idle":"2023-04-11T09:46:49.558751Z","shell.execute_reply.started":"2023-04-11T09:46:49.549242Z","shell.execute_reply":"2023-04-11T09:46:49.557640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def test_model(model, dataloader, device):\n    model.eval()\n    ssim_score = 0\n    psnr_score = 0\n    with torch.no_grad():\n        for i, data in enumerate(dataloader, 0):\n            input_img, target = data['input_img'].to(device), data['target'].to(device)\n            output = model(input_img)\n            ssim_score += ssim(output, target, data_range=1.0, size_average=False)\n            psnr_score += 10 * log10(1.0 / mean_squared_error(output, target))\n    \n    avg_ssim = ssim_score / len(dataloader)\n    avg_psnr = psnr_score / len(dataloader)\n    \n    return avg_ssim, avg_psnr","metadata":{"execution":{"iopub.status.busy":"2023-04-11T09:46:49.560182Z","iopub.execute_input":"2023-04-11T09:46:49.560749Z","iopub.status.idle":"2023-04-11T09:46:49.573632Z","shell.execute_reply.started":"2023-04-11T09:46:49.560713Z","shell.execute_reply":"2023-04-11T09:46:49.572618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Function","metadata":{}},{"cell_type":"code","source":"def main(data_dir):\n    epochs = 30\n    batch_size = 16\n    learning_rate = 0.00001\n    \n\n    transform = transforms.Compose([ToTensor()])\n    data = EUVP_Dataset(data_dir, transform=transform)\n    train_data, val_data = random_split(data, [int(0.8 * len(data)), int(0.2 * len(data))])\n    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=False)\n    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n    \n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = UnderwaterCNN().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = torch.nn.MSELoss()\n    best_psnr = 0\n    best_ssim = 0\n    for epoch in range(epochs):\n        model.train()\n        for i, sample in enumerate(train_dataloader):\n            hazy = sample['hazy'].to(device)\n            clean = sample['clean'].to(device)\n            output = model(hazy)\n\n            loss = criterion(output, clean)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        \n    model.eval()  \n    val_loss = 0\n    with torch.no_grad():\n        avg_psnr = 0\n        avg_ssim = 0\n        epoch_dir = os.path.join(output_dir, f'epoch_{epoch}')\n        os.makedirs(epoch_dir, exist_ok=True)\n        for j, sample in enumerate(val_dataloader):\n            hazy = sample['hazy'].to(device)\n            clean = sample['clean'].to(device)\n            output = model(hazy)\n\n            for k in range(output.shape[0]):\n                output_img = output[k].cpu().numpy().transpose(1, 2, 0)\n                output_img = np.clip(output_img, 0, 1)\n                output_path = os.path.join(epoch_dir, f'batch_{j}_output_{k}.png')\n                skimage.io.imsave(output_path, output_img)\n\n                input_img = hazy[k].cpu().numpy().transpose(1, 2, 0)\n                input_img = np.clip(input_img, 0, 1)\n                input_path = os.path.join(output_dir, f'batch_{j}_input_{k}.png')\n                skimage.io.imsave(input_path, input_img)\n\n            val_loss += criterion(output, clean).item()\n            avg_psnr += compare_psnr(clean.cpu().numpy(), output.cpu().numpy())\n            avg_ssim += compare_ssim(clean.cpu().numpy(), output.cpu().numpy(), multichannel=True, win_size=3)\n\n\n        avg_psnr = avg_psnr / len(val_dataloader)\n        avg_ssim = avg_ssim / len(val_dataloader)\n        val_loss = val_loss / len(val_dataloader)\n\n    if avg_psnr > best_psnr:\n        best_psnr = avg_psnr\n        torch.save(model.state_dict(), 'best_psnr.pth')\n    if avg_ssim > best_ssim:\n        best_ssim = avg_ssim\n        torch.save(model.state_dict(), 'best_ssim.pth')\n\n    print(\"Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, PSNR: {:.4f}, SSIM: {:.4f}\".format(epoch+1, loss.item(), val_loss, avg_psnr, avg_ssim))\n\n\nif __name__ == '__main__':\n  main(data_dir)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-11T09:46:49.575559Z","iopub.execute_input":"2023-04-11T09:46:49.576533Z","iopub.status.idle":"2023-04-11T12:41:42.512282Z","shell.execute_reply.started":"2023-04-11T09:46:49.576497Z","shell.execute_reply":"2023-04-11T12:41:42.510941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r file.zip /kaggle/working/","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-04-11T12:41:42.515849Z","iopub.execute_input":"2023-04-11T12:41:42.516311Z","iopub.status.idle":"2023-04-11T12:42:00.420156Z","shell.execute_reply.started":"2023-04-11T12:41:42.516264Z","shell.execute_reply":"2023-04-11T12:42:00.418633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(r'/kaggle/working') ","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:42:00.422922Z","iopub.execute_input":"2023-04-11T12:42:00.423460Z","iopub.status.idle":"2023-04-11T12:42:00.429923Z","shell.execute_reply.started":"2023-04-11T12:42:00.423406Z","shell.execute_reply":"2023-04-11T12:42:00.428543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:42:00.432257Z","iopub.execute_input":"2023-04-11T12:42:00.433229Z","iopub.status.idle":"2023-04-11T12:42:00.442609Z","shell.execute_reply.started":"2023-04-11T12:42:00.433176Z","shell.execute_reply":"2023-04-11T12:42:00.441139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2023-04-11T12:42:00.445086Z","iopub.execute_input":"2023-04-11T12:42:00.446345Z","iopub.status.idle":"2023-04-11T12:42:00.464274Z","shell.execute_reply.started":"2023-04-11T12:42:00.446289Z","shell.execute_reply":"2023-04-11T12:42:00.462621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}